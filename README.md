Grammatical Error Correction (GEC) involves the automatic correction of various types 
of grammatical errors, including spelling, punctuation and grammar. In order to convert 
an incorrect sentence to the correct version, a GEC system usually requires the input of 
the sentence itself. There are many approaches to grammatical error correction, ranging 
from rule-based models to neural machine translation. This thesis delves into the field of 
natural language processing by exploring the detailed setup of the T5-based Text-to-Text 
Transfer Transformer (T5) model for the specific task of grammatical correction. Accurate 
grammatical correction is paramount for effective communication, especially for non
native speakers of a language. This research aims to harness the power of the productive 
capabilities of the T5 model and transfer learning to develop an efficient and flexible 
system for automated grammatical correction in written text. It involves the detail of a pre
trained T5 model on a custom dataset containing sentences with varying degrees of 
grammatical errors. Data preprocessing involves encoding the sentences in the T5 
format, allowing it to generate corrected sentences for input with grammatical errors. The 
results show the effectiveness of the improved T5 model in grammatical correction. The 
model achieves competitive performance on benchmarking metrics, outperforming 
existing methods in terms of accuracy and contextual understanding. The findings 
highlight the importance of using pre-trained models and detail techniques to develop 
sophisticated grammar correction systems. In conclusion, this study highlights the ability 
of an improved T5 model in addressing the challenges of grammar correction. The 
insights gained pave the way for future research to improve architectural models and 
expand the scope of automated language correction applications.
